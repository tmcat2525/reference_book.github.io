---
layout: post
title:  "AWS SAA 合格対策参考書（SAA-C03対応） - Part 5"
date:   2025-04-26 00:03:16 +0900
categories: jekyll update
---
AWS認定 ソリューションアーキテクト アソシエイト 合格対策参考書（SAA-C03対応） - Part 5
第9章: 運用と自動化 (CloudWatch, CloudFormation, Systems Manager, Elastic Beanstalk, Service Catalog)
9.1 分野概要
AWS環境の効率的な運用と管理には、監視、自動化、構成管理が不可欠です。この章では、リソースとアプリケーションの監視を行うCloudWatch、インフラ構成をコードで管理・自動デプロイするCloudFormation、OS設定やパッチ適用などを管理するSystems Manager、アプリケーションのデプロイと管理を簡素化するElastic Beanstalk、承認済みITサービスのカタログを提供するService Catalogなど、運用管理と自動化に役立つサービスを学びます。

9.2 主要AWSサービス解説
Amazon CloudWatch:

AWSリソースとアプリケーションのモニタリングおよびオブザーバビリティサービス。
メトリクス（CPU使用率、ネットワークI/O、リクエスト数など）を収集・追跡・可視化。標準メトリクスとカスタムメトリクスがある。
ログ（CloudWatch Logs）を集約・監視・分析。CloudWatch AgentでEC2やオンプレミスの詳細ログ（OSレベル、アプリログ）を収集可能。
アラームを設定し、メトリクスの閾値超過や特定ログパターンを検知してアクション（SNS通知、Auto Scalingアクションなど）を実行。
ダッシュボードでメトリクスとログをカスタマイズして表示。
Container Insights: コンテナ環境（ECS, EKS）の詳細なメトリクスとログを収集・集約・要約。
重要キーワード: モニタリング, オブザーバビリティ, メトリクス, CloudWatch Logs, CloudWatch Agent, アラーム, ダッシュボード, Container Insights
AWS CloudFormation:

Infrastructure as Code (IaC) を実現するサービス。インフラ構成（VPC, EC2, S3, RDSなど）をテンプレート（JSON/YAML形式）で記述し、スタックとして自動的にプロビジョニング・管理。
テンプレートを再利用して、同じ構成を繰り返し迅速かつ一貫性を持ってデプロイ可能。
変更セットで、スタック更新前に変更内容の影響をプレビュー。
ドリフト検出で、テンプレート外で行われた設定変更（ドリフト）を検出。
StackSets: 複数のAWSアカウントやリージョンにわたってスタックを作成・更新・削除。
重要キーワード: IaC (Infrastructure as Code), テンプレート, スタック, リソース, パラメータ, マッピング, 条件, 出力, 変更セット, ドリフト検出, StackSets
AWS Systems Manager:

AWSおよびオンプレミスのインフラストラクチャの運用管理を一元化・自動化するサービス群。
パラメーターストア: 設定データやシークレット（パスワード、ライセンスキーなど）を安全に保存・管理。
Session Manager: ブラウザやCLIからEC2インスタンスやオンプレミスサーバーへSSH/RDPポートを開けずに安全にアクセス。
Patch Manager: OSのパッチ適用を自動化。
Run Command: 複数のインスタンスに対してコマンドをリモート実行。
Automation: 運用タスク（AMI作成、パッチ適用など）を自動化するランブックを作成・実行。
重要キーワード: 運用管理, 自動化, パラメーターストア, Session Manager, Patch Manager, Run Command, Automation
AWS Elastic Beanstalk:

Webアプリケーションやサービスのデプロイとスケーリングを簡素化するPaaS (Platform as a Service) ライクなサービス。
開発者がアプリケーションコードをアップロードするだけで、キャパシティプロビジョニング、負荷分散、Auto Scaling、ヘルスモニタリングなどのインフラ管理が自動化される。
Java, .NET, PHP, Node.js, Python, Ruby, Go, Dockerなど多くのプラットフォームをサポート。
基盤となるAWSリソース（EC2, ELB, Auto Scaling, RDSなど）へのアクセスやカスタマイズも可能。内部的にCloudFormationを使用。
重要キーワード: アプリケーションデプロイ, PaaS, 自動化, プラットフォームサポート, 環境管理
AWS Service Catalog:

組織がAWS上で使用を承認したITサービス（製品）のカタログを作成・管理し、ユーザーがセルフサービスでプロビジョニングできるようにするサービス。
IT管理者はCloudFormationテンプレートなどを基に製品を定義し、ポートフォリオにまとめてユーザーやグループに共有。
ユーザーはコンプライアンスやガバナンスに準拠した形で、承認されたリソースを迅速に利用開始できる。
タグ付け、コスト管理、アクセス制御などのガバナンスを強制。
重要キーワード: ITサービスカタログ, セルフサービスプロビジョニング, ガバナンス, コンプライアンス, 製品, ポートフォリオ
9.3 問題演習とポイント解説
(問題11より)

[ポイント] アプリケーション開発・テスト環境のように、インフラ構成を迅速にプロビジョニングし、容易に削除したい場合、AWS CloudFormationが最適です。テスト環境に必要なリソース（VPC, EC2, RDSなど）をテンプレートとして定義しておけば、コマンド一つまたはコンソール操作で環境全体を再現・削除できます。CodePipelineはCI/CDパイプライン構築、AMI/BashスクリプトはEC2固有の設定、ECRはコンテナイメージ管理が主目的です。
出題傾向: CloudFormationの基本的なユースケース。Infrastructure as Codeによる環境再現性と管理効率化。
重要キーワード: CloudFormation, テンプレート, スタック, Infrastructure as Code (IaC), 環境プロビジョニング
(問題44 (運用)より)

[ポイント] Redshiftクラスターに出入りするCOPY/UNLOADトラフィックをVPCフローログなどで監視・制御したい場合、拡張VPCルーティングを有効にする必要があります。これを有効にすると、これらのトラフィックが必ずVPCを経由するようになり、セキュリティグループやNACL、VPCエンドポイントなどのVPC機能でトラフィックを管理できるようになります。監査ログやRedshift Spectrumは異なる目的の機能です。
出題傾向: Redshiftの拡張VPCルーティングの目的と効果。VPC機能との連携によるセキュリティ強化。
重要キーワード: Redshift, 拡張VPCルーティング, COPY/UNLOADトラフィック, VPC連携
(問題57 (運用)より)

[ポイント] AWS環境（EC2やオンプレミス）の運用管理を一元化し、OSレベルのメトリクス収集、パッチ管理、コマンド実行などを効率化したい場合、AWS Systems Managerの利用が適しています。EC2はアンマネージド型でありOS管理はユーザー責任ですが、Systems Managerはその運用を支援します。EMRはビッグデータ処理、NeptuneはグラフDB、DynamoDBはNoSQL DBであり、運用管理ツールではありません。
出題傾向: Systems Managerの概要とユースケース。統合的な運用管理。
重要キーワード: AWS Systems Manager, 運用管理一元化, パッチ管理, コマンド実行
(問題5 (運用)より)

[ポイント] 複数のEC2インスタンスやオンプレミスサーバーからログファイル（アプリケーションログ、システムログなど）を収集・集約し、中央で監視・分析したい場合、CloudWatch LogsとCloudWatchエージェントを使用します。各サーバーにCloudWatchエージェントをインストールし、収集したいログファイルと転送先のCloudWatch Logsロググループを指定します。これにより、ログを一元管理できます。VPCフローログはネットワークトラフィック、CloudTrailはAPIコールログ、Configは設定変更ログが対象です。
出題傾向: ログ収集・集約の方法。CloudWatch LogsとAgentの役割。
重要キーワード: CloudWatch Logs, CloudWatch Agent, ログ収集, 中央ロギング
(問題27 (環境自動化)より)

[ポイント] CloudFormationテンプレートには、テンプレートの形式バージョン、説明、パラメータ（実行時に入力する値）、マッピング（条件に応じた値の選択）、条件（リソース作成の判断）、リソース（作成するAWSリソース定義、必須）、出力（スタック作成後に表示する値）などのセクションがあります。Dependenciesというセクションは存在しません（リソース間の依存関係はDependsOn属性などで定義）。
出題傾向: CloudFormationテンプレートの主要なセクションとその役割の理解。
重要キーワード: CloudFormationテンプレートセクション (Parameters, Mappings, Conditions, Resources, Outputs)
(問題40 (環境自動化)より)

[ポイント] CloudFormation StackSetsを使用すると、単一のCloudFormationテンプレートから、複数のAWSアカウントや複数のAWSリージョンにわたってスタック（リソース群）を一元的に作成、更新、削除できます。組織全体の標準構成を展開したり、DR環境を複数リージョンに展開したりする際に非常に便利です。通常のテンプレートや変更セットは単一アカウント/リージョンが対象です。
出題傾向: CloudFormation StackSetsのユースケース。マルチアカウント/マルチリージョンでのインフラ展開自動化。
重要キーワード: CloudFormation StackSets, マルチアカウント管理, マルチリージョン展開
(問題42 (環境自動化)より)

[ポイント] AWS Elastic Beanstalkは、Webアプリケーションのデプロイと管理を大幅に簡素化するサービスです。開発者はコードをアップロードするだけで、Elastic Beanstalkが自動的にインフラ（EC2, ELB, Auto Scaling, RDSなど）をプロビジョニングし、アプリケーションをデプロイ、監視します。基盤インフラの管理（パッチ適用、スケーリングなど）も自動化されるため、運用負荷が大幅に軽減されます。複数AZへのデプロイも容易に設定可能です。CloudFormationはより低レベルなインフラ定義に使われます。
出題傾向: Elastic Beanstalkのメリットとユースケース。PaaSライクなアプリケーションデプロイ・管理の簡素化。
重要キーワード: AWS Elastic Beanstalk, アプリケーションデプロイ自動化, PaaS
(問題43 (環境自動化)より)

[ポイント] 組織内で承認されたAWSリソース構成（ソリューションセット、例：特定のEC2タイプとRDS構成）をカタログ化し、エンドユーザー（例：各店舗、開発チーム）がセルフサービスで、かつガバナンス（アクセス制御、タグ付けルールなど）を効かせた形でデプロイできるようにしたい場合、AWS Service Catalogを使用します。管理者は製品とポートフォリオを作成・管理し、ユーザーはポータルから承認済み製品を選択して起動します。Elastic Beanstalkはアプリデプロイ、CloudFormationはインフラ定義、Marketplaceはサードパーティ製品の提供が主目的です。
出題傾向: Service Catalogのユースケース。承認済みITサービスのカタログ化とセルフサービス提供、ガバナンス強化。
重要キーワード: AWS Service Catalog, ITサービスカタログ, セルフサービス, ガバナンス
9.4 学習Tips
IaCの概念: CloudFormationのようなInfrastructure as Codeツールを使うメリット（再現性、一貫性、バージョン管理、自動化）を理解しましょう。
監視の目的: CloudWatchで何を監視（メトリクス、ログ）し、なぜ監視するのか（パフォーマンス把握、異常検知、トラブルシューティング）を意識しましょう。アラームとアクションの連携が重要です。
運用自動化ツール: Systems Managerの各機能（パラメーターストア、Session Manager、Patch Manager、Run Command、Automation）がどのような運用タスクを自動化・効率化するのか、具体的なユースケースを覚えましょう。
PaaS vs IaaS: Elastic Beanstalk (PaaSライク)とEC2/CloudFormation (IaaS)のどちらを選択するかは、開発・運用の自由度と管理負荷のトレードオフになります。
9.5 理解度チェックテスト
(選択式)

複数のAWSアカウントやリージョンにわたって、同じCloudFormationテンプレートに基づいたインフラ構成を一元的にデプロイ・管理したい場合、どのCloudFormation機能を使用しますか？
a) 変更セット (Change Sets)
b) ドリフト検出 (Drift Detection)
c) スタックセット (StackSets)
d) ネストされたスタック (Nested Stacks)

EC2インスタンスにSSHポートを開けずに、安全にリモートシェルアクセスを提供するためのAWS Systems Managerの機能はどれですか？
a) Patch Manager
b) Run Command
c) Session Manager
d) Parameter Store

(短記述式)

AWS Elastic Beanstalkを使用する主なメリットを2つ挙げてください。
(解答例)

c) スタックセット (StackSets)
c) Session Manager
AWS Elastic Beanstalkの主なメリット：
デプロイの簡素化: 開発者はアプリケーションコードをアップロードするだけで、インフラのプロビジョニングや設定、アプリケーションのデプロイが自動的に行われる。
運用負荷の軽減: キャパシティプロビジョニング、負荷分散、Auto Scaling、OSパッチ適用、アプリケーションのヘルスモニタリングなどのインフラ管理タスクが自動化される。
迅速な開発サイクル: インフラ管理の手間が省けるため、開発者はアプリケーション開発に集中でき、開発・デプロイのサイクルを早めることができる。
9.6 頻出キーワード
CloudWatch / CloudWatch Logs / CloudWatch Agent
メトリクス / アラーム / ダッシュボード
Container Insights
CloudFormation / テンプレート / スタック / IaC
変更セット / ドリフト検出 / StackSets
Systems Manager / Parameter Store / Session Manager / Patch Manager / Run Command / Automation
Elastic Beanstalk / PaaS / アプリケーションデプロイ
Service Catalog / 製品 / ポートフォリオ / ガバナンス
運用管理 / 自動化 / 監視 / オブザーバビリティ
第10章: コスト最適化
10.1 分野概要
AWSの利用料金は基本的に従量課金ですが、リソースの選択や設定、購入方法によってコストは大きく変動します。この章では、AWS利用におけるコストの考え方、コストを可視化・分析するためのツール（Cost Explorer, Budgetsなど）、そしてコストを削減するための具体的な戦略（適切なサイジング、購入オプションの活用、不要リソースの削除、アーキテクチャの見直しなど）について学びます。コスト最適化は継続的なプロセスです。

10.2 主要AWSサービス・概念解説
AWS Cost Explorer:
AWSのコストと使用状況を可視化・分析するためのツール。
時間経過に伴うコストの傾向、サービス別・タグ別などの内訳、RI/Savings Plansの推奨などを表示。
カスタムレポートを作成し、コストドライバーを特定。
AWS Budgets:
コストまたは使用量が予算額（閾値）を超えた場合、または超えると予測された場合にアラート（SNS通知、Eメール）を送信する機能。
コストの想定外の増加を早期に検知。RI/Savings Plansのカバレッジや使用率の追跡も可能。
AWS Cost and Usage Report (CUR):
AWSのコストと使用状況に関する最も詳細なデータを提供するレポート。
時間単位または日単位の明細データをS3バケットに出力。AthenaやQuickSight、サードパーティツールでの詳細分析に利用。
EC2購入オプション: (第1章も参照)
オンデマンド: 従量課金。柔軟性が高い。
リザーブドインスタンス(RI): 1年/3年の長期利用コミットで大幅割引。スタンダード（変更制限あり）とコンバーティブル（柔軟性あり）がある。
Savings Plans: 一定のコンピューティング使用量（$/時間）を1年/3年コミットすることで割引。EC2, Fargate, Lambdaに適用可。Compute SP（柔軟性高）とEC2 Instance SP（割引率高）。RIより柔軟性が高い場合が多い。
スポットインスタンス: 大幅割引（最大90%）。中断可能性あり。中断耐性のあるワークロード向け。
適切なサイジング (Right Sizing):
CloudWatchメトリクスなどを分析し、ワークロードに必要な最小限の性能を持つインスタンスタイプやボリュームサイズを選択すること。オーバースペックなリソースはコストの無駄。
ストレージクラスの最適化: (第2章も参照)
S3やEBSで、アクセス頻度やデータ保持期間に応じて最適なストレージクラスを選択すること。ライフサイクル管理の活用。
不要リソースの削除:
使用していないEC2インスタンス、アタッチされていないEBSボリューム、古いスナップショット、アイドル状態のELBなどを定期的に特定し削除。
サーバーレスアーキテクチャの活用: (第6章も参照)
Lambda, API Gateway, SQS, DynamoDBなど、リクエストや実行時間に応じた課金のサービスを利用することで、アイドル時のコストを削減。
データ転送コストの考慮:
リージョン間、AZ間、インターネットへのデータ転送にはコストが発生する場合がある。VPCエンドポイントの活用やCloudFrontによるキャッシュで削減可能。
重要キーワード: コスト最適化, Cost Explorer, Budgets, Cost and Usage Report (CUR), 購入オプション(オンデマンド/RI/Savings Plans/スポット), 適切なサイジング, ストレージクラス, ライフサイクル管理, 不要リソース削除, サーバーレス, データ転送コスト
10.3 問題演習とポイント解説
(問題1 (Redshift)より)

[ポイント] Redshiftのコスト削減には、ノードタイプ/数の見直し、リザーブドノード購入（長期利用の場合）、不要なスナップショット削除、クラスターの一時停止（利用しない時間帯）などが有効です。
出題傾向: 特定サービスのコスト削減策。Redshiftの課金要素（ノード時間、ストレージ）の理解。
重要キーワード: Redshiftコスト削減, スナップショット管理, リザーブドノード
(問題20 (EC2)より)

[ポイント] スポットインスタンスは中断可能なバッチ処理など、時間に柔軟なワークロードのコスト最適化に非常に有効です。リザーブドインスタンスは長期安定稼働向け、オンデマンドは柔軟性重視です。
出題傾向: EC2購入オプションのユースケースとコスト効果。
重要キーワード: スポットインスタンス, コスト最適化
(問題59 (EC2)より)

[ポイント] アプリケーションの利用期間と負荷パターンに応じてEC2購入オプションを組み合わせます。常時稼働するベースライン負荷にはリザーブドインスタンス（またはSavings Plans）を適用し、変動する負荷や一時的な利用にはオンデマンドインスタンスやスポットインスタンス（中断許容なら）、キャパシティー予約（確実な確保が必要な場合）を使い分けるのがコスト効率の良い戦略です。
出題傾向: 混合利用シナリオでの最適な購入オプションの組み合わせ。
重要キーワード: 購入オプション組み合わせ, リザーブドインスタンス, オンデマンドインスタンス, キャパシティー予約
(問題1 (コスト)より)

[ポイント] AWS Organizationsの一括請求（コンソリデーティッドビリング） のメリットの一つは、組織全体のAWS利用量を合算してボリュームディスカウント（例：S3のストレージ料金、データ転送料金など）の恩恵を受けやすくなることです。これにより、個別アカウントで利用するよりもコストを削減できる可能性があります。無料利用枠はアカウントごと、請求比重設定はありません。
出題傾向: AWS Organizationsの一括請求のメリット。ボリュームディスカウント。
重要キーワード: AWS Organizations, 一括請求, ボリュームディスカウント
(問題6 (コスト)より)

[ポイント] AWSサービスの中には、EC2やRDSと同様にリザーブド購入オプションを提供しているものがあります。DynamoDBリザーブドキャパシティ、Redshiftリザーブドノード、ElastiCacheリザーブドキャッシュノードなどが該当します。これらを利用することで、対応するサービスのコストを削減できます。S3やEFSにはリザーブドオプションはありません（Savings Plansは適用可能な場合あり）。
出題傾向: リザーブド購入オプションが利用可能なサービスの知識。
重要キーワード: リザーブドキャパシティ/ノード (DynamoDB, Redshift, ElastiCache)
(問題7 (コスト)より)

[ポイント] AWS Organizationsの一括請求環境では、マスターアカウント（管理アカウント）で購入したリザーブドインスタンス(RI) やSavings Plansの割引特典は、組織内の他のメンバーアカウントでも利用可能です（共有設定による）。RIが余っていれば、他のアカウントのオンデマンドインスタンス利用料金に自動的に適用され、コスト削減に繋がります。
出題傾向: RI/Savings Plansの共有機能。一括請求環境でのコストメリット。
重要キーワード: RI/Savings Plans共有, 一括請求
(問題15 (コスト)より)

[ポイント] AWSのコストが発生する要因としない要因を理解することが重要です。
コスト発生: 実行中のEC2インスタンス、アタッチされているEBSボリューム（インスタンス停止中でも）、データ転送（アウトバウンド、リージョン間など）、S3ストレージ、RDS稼働時間、NATゲートウェイ利用など。
コスト非発生（基本）: VPC自体、IAM、セキュリティグループ、ネットワークACL、CloudFormation、Auto Scalingグループ自体（起動したインスタンスは課金）、停止中のオンデマンドEC2（EBS除く）など。 停止中のEC2でもアタッチされたEBSボリュームには課金が続く点に注意が必要です。
出題傾向: 課金対象となるAWSリソース・操作の特定。コスト削減のための対象特定。
重要キーワード: 課金対象リソース, 停止中インスタンスの課金 (EBS), データ転送コスト
(問題57 (コスト)より)

[ポイント] 長期間（3年）利用するLambdaやFargate、EC2などのコンピューティングリソースのコストを最適化するには、Compute Savings Plansが有効です。特定のインスタンスファミリーに縛られず、リージョン内で柔軟に割引を適用できます。スポットインスタンスは中断可能性があるため、常時稼働のフロントエンドには不向きな場合があります。リザーブドインスタンスはEC2/RDS向けです。
出題傾向: Savings Plans（特にCompute Savings Plans）のメリットと適用範囲。柔軟なコミットメントによるコスト削減。
重要キーワード: Savings Plans (Compute SP / EC2 Instance SP), 長期利用コミットメント
10.4 学習Tips
主要サービスの課金体系: EC2（インスタンス時間、データ転送）、S3（ストレージ容量、リクエスト数、データ転送）、RDS（インスタンス時間、ストレージ、IOPS）、Lambda（リクエスト数、実行時間）、DynamoDB（キャパシティユニット、ストレージ）など、よく使うサービスの基本的な課金モデルを理解しましょう。
コスト管理ツール: Cost ExplorerとBudgetsは実際に触ってみるのが一番です。自分の（無料利用枠内の）アカウントでコストを確認し、予算アラートを設定してみましょう。
最適化はバランス: コスト削減だけを追求すると、パフォーマンスや可用性が犠牲になることがあります。要件を満たしつつ、費用対効果の高い構成を目指す視点が重要です。
継続的な見直し: ワークロードの変化やAWSの新しいサービス・料金体系に合わせて、定期的にコストを見直し、最適化を続けることが大切です。
10.5 理解度チェックテスト
(選択式)

AWSの利用料金が予期せず増加するのを防ぐために、設定した予算額を超過しそうになった際にアラートを受け取るのに最も適したサービスはどれですか？
a) AWS Cost Explorer
b) AWS Budgets
c) AWS Cost and Usage Report (CUR)
d) AWS Trusted Advisor

1年間の安定した利用が見込まれるEC2インスタンスに対して、最も割引率が高い購入オプション（支払い方法含む）は一般的にどれですか？
a) オンデマンドインスタンス
b) 1年契約 スタンダードリザーブドインスタンス（前払いなし）
c) 1年契約 スタンダードリザーブドインスタンス（全額前払い）
d) 1年契約 コンバーティブルリザーブドインスタンス（全額前払い）

(短記述式)

EC2インスタンスのコストを最適化するための「適切なサイジング（Right Sizing）」とは何か、簡単に説明してください。
(解答例)

b) AWS Budgets
c) 1年契約 スタンダードリザーブドインスタンス（全額前払い）
適切なサイジング（Right Sizing）とは、アプリケーションやワークロードが必要とする性能（CPU、メモリ、ネットワークなど）をCloudWatchなどのモニタリングデータに基づいて分析し、過剰なスペック（オーバースペック）を持つリソースを避け、要件を満たす最小限の性能を持つインスタンスタイプやボリュームサイズを選択することです。これにより、不要なコストを削減します。
10.6 頻出キーワード
コスト最適化
従量課金
AWS Cost Explorer
AWS Budgets
AWS Cost and Usage Report (CUR)
購入オプション (オンデマンド, リザーブドインスタンス(RI), Savings Plans, スポットインスタンス)
スタンダードRI / コンバーティブルRI
Compute Savings Plans / EC2 Instance Savings Plans
適切なサイジング (Right Sizing)
ストレージクラス最適化
ライフサイクル管理
不要リソース削除
サーバーレス
データ転送コスト
AWS Organizations / 一括請求
ボリュームディスカウント
タグ（コスト配分タグ）
第11章: 機械学習と分析 (Rekognition, Transcribe, Translate, Comprehend, Forecast, SageMaker, Athena, EMR, Glue, Lake Formation, Macie, OpenSearch)
11.1 分野概要
データから価値を引き出すための分析や、画像・音声・テキストなどを認識・処理する機械学習(ML)は、現代のアプリケーションにおいて重要度を増しています。AWSは、専門知識がなくても利用できるAIサービス（Rekognition, Transcribe, Translate, Comprehend, Forecast, Lex, Pollyなど）、MLモデル開発プラットフォームSageMaker、データレイク構築・管理のLake Formation、ETL処理のGlue、データウェアハウスのRedshift、インタラクティブクエリのAthena、ビッグデータ処理基盤のEMR、検索エンジンのOpenSearch Service、機密データ検出のMacieなど、多岐にわたるサービスを提供しています。

11.2 主要AWSサービス解説 (抜粋)
Amazon Rekognition: 画像および動画分析サービス。物体・シーン検出、顔認識・分析、不適切コンテンツ検出、テキスト検出などが可能。APIを呼び出すだけで利用可能。
Amazon Transcribe: 音声ファイルをテキストに変換する自動音声認識(ASR)サービス。リアルタイム処理も可能。話者分離、カスタム語彙、PIIリダクション機能など。
Amazon Translate: ニューラル機械翻訳サービス。多言語間のテキストをリアルタイムまたはバッチで翻訳。
Amazon Comprehend: テキストデータからインサイト（エンティティ、キーフレーズ、感情、言語など）を抽出する自然言語処理(NLP)サービス。Comprehend Medicalは医療テキストに特化。
Amazon Forecast: 機械学習を使用して高精度な時系列予測（売上予測、需要予測など）を行うフルマネージドサービス。過去データから自動でモデルを構築・学習。
Amazon SageMaker: 機械学習モデルの構築、トレーニング、デプロイをエンドツーエンドで行うための統合開発環境・プラットフォーム。データサイエンティストやML開発者向け。
Amazon Athena: (第3章も参照) S3データレイク上のデータを標準SQLでインタラクティブに分析できるサーバーレスクエリサービス。
Amazon EMR (Elastic MapReduce): (第3章も参照) Apache Spark, Hadoop, PrestoなどのビッグデータフレームワークをAWS上で容易に実行・管理できるクラスターサービス。大規模バッチ処理、ストリーム処理、インタラクティブ分析などに利用。
AWS Glue: サーバーレスのETL (抽出、変換、ロード)およびデータカタログサービス。データソースをクロールしてスキーマを自動検出し、データカタログを作成。Python/SparkベースのETLジョブを視覚的に作成・実行。Glue DataBrewはコード不要のデータ準備ツール。Glue Sensitive Data Detectionは機密データ検出。
AWS Lake Formation: 安全なデータレイクを数日で構築・管理するためのサービス。S3を基盤とし、Glueデータカタログと連携。データアクセス権限（テーブル/列レベル）を一元管理。
Amazon Macie: 機械学習を利用してS3バケット内の機密データ（PIIなど） を自動的に検出・分類・保護するサービス。データセキュリティとプライバシーコンプライアンスを支援。
Amazon OpenSearch Service (旧 Elasticsearch Service): OpenSearchおよびElasticsearchをAWS上でデプロイ・運用・スケールするためのマネージドサービス。ログ分析、リアルタイムアプリケーションモニタリング、全文検索などに利用。
重要キーワード: 機械学習(ML), 人工知能(AI), 画像認識(Rekognition), 音声認識(Transcribe), 機械翻訳(Translate), 自然言語処理(NLP)(Comprehend), 時系列予測(Forecast), MLプラットフォーム(SageMaker), データレイク(Lake Formation), ETL(Glue), データカタログ(Glue), サーバーレスクエリ(Athena), ビッグデータ処理(EMR), 検索エンジン(OpenSearch), 機密データ検出(Macie)
11.3 問題演習とポイント解説
(問題53 (Database)より)

[ポイント] ドキュメント（PDFなど）を大量に保存し、内容に対してフレーズ検索（全文検索）機能を提供したい場合、Amazon S3にドキュメントを保存し、Amazon OpenSearch Service（旧Elasticsearch Service）と連携させる構成が一般的です。S3のデータをOpenSearchにインデックス化し、OpenSearchの強力な検索機能を利用します。AthenaやS3 Select、Redshiftは主に構造化/半構造化データに対するSQLベースの分析が主体であり、文書内のフレーズ検索にはOpenSearchが適しています。
出題傾向: 全文検索エンジンのユースケース。OpenSearch Serviceの役割。S3との連携。
よく出るサービスの組み合わせ: S3 + OpenSearch Service (+ Lambdaなどでインデックス連携)
重要キーワード: Amazon OpenSearch Service, 全文検索, フレーズ検索, インデックス
(問題2 (AI)より)

[ポイント] 複数のAIサービスを組み合わせてソリューションを構築する問題。
音声→テキスト変換: Amazon Transcribe
テキスト翻訳: Amazon Translate
テキスト感情分析: Amazon Comprehend これらのマネージドAIサービスをAPI経由で呼び出すことで、専門知識がなくても高度な機能を利用できます。Lexは対話型AI（チャットボット）、Pollyはテキスト→音声変換、SageMakerはモデル開発プラットフォームです。
出題傾向: 各AIサービスの主要機能と適切なユースケースの選択。サービス連携。
重要キーワード: Transcribe (音声→テキスト), Translate (翻訳), Comprehend (テキスト分析/感情分析), Lex (チャットボット), Polly (テキスト→音声)
(問題12 (AI)より)

[ポイント] 問題2と同様、AIサービスの組み合わせ問題。Amazon TextractはOCR（光学文字認識）により文書（画像やPDF）からテキストや構造（フォーム、テーブル）を抽出します。抽出されたテキストに対してAmazon Comprehendで内容分析（エンティティ抽出、感情分析など）を行うことができます。AthenaはSQLクエリサービスです。
出題傾向: TextractによるOCRとComprehendによるNLPの連携。
よく出るサービスの組み合わせ: Textract + Comprehend (+ S3 + Lambdaなど)
重要キーワード: Amazon Textract (OCR), Amazon Comprehend (NLP)
(問題21 (AI)より)

[ポイント] 音声データからテキストを抽出する際に、個人を特定できる情報（PII）を自動的にマスキング（編集） したい場合、Amazon TranscribeのPIIリダクション機能を使用します。文字起こしジョブの設定でこの機能を有効にすると、氏名、住所、電話番号、クレジットカード番号などのPIIが[PII]のような形式で置き換えられたテキストが出力されます。Kinesis Video Streamsは動画ストリーム処理、Textractは文書OCRです。
出題傾向: Transcribeの高度な機能（PIIリダクションなど）。コンプライアンス要件への対応。
重要キーワード: Amazon Transcribe, PIIリダクション, 個人情報保護
(問題62 (Analytics)より)

[ポイント] オンプレミスや他のソースから収集した生データ（例：S3に保存）を分析可能な形式に変換・準備（ETL） し、データレイクやデータウェアハウスで利用できるようにするには、AWS Glueが中心的な役割を果たします。
Glueクローラー: データソース（S3など）をスキャンし、スキーマ情報を自動検出してGlueデータカタログにメタデータとして登録。
Glue ETLジョブ: データカタログのメタデータを利用し、PythonまたはScala（Sparkベース）でデータ変換ロジックを記述（またはStudioで視覚的に生成）。変換後のデータをS3やRedshiftなどに出力。 その後、AthenaやRedshift SpectrumでS3上のデータ（データカタログ経由）をクエリしたり、Redshiftにロードして分析したりします。EMRもETLに利用できますが、Glueはサーバーレスでより運用が容易です。
出題傾向: データレイク/DWH構築におけるETLプロセス。AWS Glue（クローラー、データカタログ、ETLジョブ）の役割と連携。
よく出るサービスの組み合わせ: S3 + Glue (Crawler, Data Catalog, ETL) + Athena/Redshift Spectrum
重要キーワード: AWS Glue, ETL, Glueクローラー, Glueデータカタログ, Glue ETLジョブ, データ準備
(問題64 (AI)より)

[ポイント] 手書き文書を含むドキュメントからテキストを抽出し（OCR）、さらにそのテキストから医療関連情報（病状、治療、投薬、個人情報など）を抽出・構造化したい場合、Amazon TextractでOCR処理を行った後、Amazon Comprehend Medicalで医療情報の抽出を行います。通常のComprehendよりも医療分野に特化したエンティティ認識などが可能です。Rekognitionは画像/動画分析、Transcribeは音声認識です。
出題傾向: TextractとComprehend Medicalの連携による医療文書処理。AIサービスの専門分野特化機能。
重要キーワード: Amazon Textract (OCR), Amazon Comprehend Medical (医療NLP)
(問題11 (Analytics)より)

[ポイント] Amazon EMRは、Apache Spark, Hadoopなどのフレームワークを用いて大規模なデータ処理・分析を行うためのプラットフォームです。S3に保存された大量のログファイルなどを処理するのに適しています。Glacierはアーカイブ用、S3 Selectは簡易フィルタリング、DynamoDB+Lambdaはデータ量や処理の複雑さによっては限界があります。
出題傾向: 大規模データ処理/ビッグデータ分析に適したサービスの選択。EMRのユースケース。
よく出るサービスの組み合わせ: S3 + EMR, EMR + Spark/Hadoop
重要キーワード: Amazon EMR, ビッグデータ処理, Apache Spark, Hadoop
(問題44 (Analytics)より)

[ポイント] 複数のデータソース（S3, RDSなど）に分散したデータを統合的に分析し、かつアクセス権限をテーブルや列レベルで細かく制御したい場合、AWS Lake Formationが有効です。Lake FormationはS3上にデータレイクを構築し、Glueデータカタログを用いてメタデータを一元管理します。そして、Lake Formation独自の権限モデル（IAMユーザー/ロールに対して許可/拒否）により、データカタログ内のテーブルや列へのアクセスを詳細に制御できます。Glue JDBC接続でRDSデータを取り込むことも可能です。RedshiftやAthena単独ではここまでの詳細な権限管理はより複雑になります。
出題傾向: データレイクにおけるデータガバナンス。Lake Formationの役割（データレイク構築、権限管理）。Glueとの連携。
重要キーワード: AWS Lake Formation, データレイク, データガバナンス, アクセス制御(テーブル/列レベル), AWS Glueデータカタログ
(問題50 (Analytics)より)

[ポイント] 外部の企業とAWS上のデータ（例：Lake Formation管理下のデータレイク）を安全かつ統制された方法で共有（提供または購読）したい場合、AWS Data Exchangeを利用します。Data Exchangeは、データプロバイダーがデータセットをカタログ化して公開し、サブスクライバーがそれを見つけてライセンスし、アクセスするためのサービスです。Lake Formationと連携し、Lake Formationの権限管理を適用したままデータ共有が可能です。GlueはETL/データカタログ、Secrets Managerは機密情報管理、Macieは機密データ検出が目的です。
出題傾向: データ共有（特に組織外部との共有）。AWS Data Exchangeのユースケース。Lake Formationとの連携。
重要キーワード: AWS Data Exchange, データ共有, データプロバイダー/サブスクライバー, Lake Formation連携
(問題51 (Analytics)より)

[ポイント] サーバーから送信され続けるログデータのようなストリーミングデータをニアリアルタイム（例：1分ごと）で収集し、データ形式を変換してからS3などの宛先に配信・保存したい場合、Amazon Kinesis Data Firehoseが最適です。FirehoseはLambda関数を統合してデータ変換処理を組み込むことができ、S3, Redshift, OpenSearchなどに容易に配信できます。分析にはAthenaが適しています。Kinesis Data Streamsはよりリアルタイム性が高い（ミリ秒単位）場合に、Lambda単独ではスケーラビリティや変換処理の管理が複雑になる可能性があります。
出題傾向: ストリーミングデータの収集・変換・配信パイプライン。Kinesis Data Firehoseの役割とLambda連携。Athenaとの連携による分析。
よく出るサービスの組み合わせ: (デバイス/サーバー) -> Kinesis Data Firehose (+ Lambda) -> S3 -> Athena
重要キーワード: Kinesis Data Firehose, ストリーミングデータ配信, データ変換(Lambda連携), S3, Athena
(問題58 (Analytics)より)

[ポイント] リアルタイムでストリーミングデータを分析し、結果をAmazon S3に出力したい場合、Amazon Managed Service for Apache Flink（旧Kinesis Data Analytics for Apache Flink）が適しています。Flinkアプリケーションを作成し、入力ストリーム（Kinesis Data StreamsやMSKなど）と出力シンク（S3, Kinesis Data Streams, Kinesis Data Firehoseなど）を指定して、ストリーム処理ロジックを実装します。S3を直接シンクとして指定できます。GlueはバッチETL、Firehoseは配信が主目的です。
出題傾向: リアルタイムストリーム分析。Managed Service for Apache Flinkのユースケース。S3シンク。
重要キーワード: Amazon Managed Service for Apache Flink, リアルタイムストリーム分析, S3シンク
(問題26 (AI)より)

[ポイント] 過去の時系列データ（例：販売実績、センサーデータ）に基づいて将来の値を予測したいが、機械学習の専門知識がない場合、Amazon Forecastを利用します。ForecastはS3などから時系列データをインポートし、複数の予測アルゴリズム（ARIMA, Prophet, DeepAR+など）を自動的に試して最適なモデルを構築・学習し、予測APIを提供します。SageMakerはより汎用的なMLプラットフォームで専門知識が必要です。Lambdaは予測モデル実行には使えますが、モデル構築は行いません。
出題傾向: 時系列予測のユースケース。Amazon Forecastの役割とメリット（自動モデル構築）。SageMakerとの違い。
重要キーワード: Amazon Forecast, 時系列予測, 自動機械学習(AutoML)
11.4 学習Tips
AI/MLサービスの分類: AWSのAI/MLサービスは多岐にわたります。①専門知識不要で使えるAPIベースの「AIサービス」（Rekognition, Transcribe, Comprehendなど）と、②モデル開発・学習・デプロイを行う「MLプラットフォーム」（SageMaker）に大別して理解すると整理しやすいです。
データ分析フロー: データ収集（Kinesis, IoT Coreなど）→ データ保存（S3データレイクなど）→ データ準備・ETL（Glue）→ データ分析（Athena, Redshift, EMR, QuickSight）→ 機械学習（SageMaker, Forecastなど）という典型的なデータ分析のパイプラインと、各段階で使われる主要サービスを把握しましょう。
Lake FormationとGlueの関係: Lake Formationはデータレイクのセキュリティとガバナンスを一元管理するサービスであり、その基盤としてGlueデータカタログを利用します。この関係性を理解することが重要です。
ユースケースで覚える: 各サービスがどのようなビジネス課題を解決するのか（例：不正検知ならFraud Detector、レコメンデーションならPersonalize、検索ならOpenSearch）を具体例と結びつけて覚えましょう。
11.5 理解度チェックテスト
(選択式)

S3データレイク上のCSVファイルに対して、サーバーレスでインタラクティブに標準SQLクエリを実行したい場合、最もコスト効率が良いサービスはどれですか？
a) Amazon Redshift
b) Amazon EMR
c) Amazon Athena
d) Amazon OpenSearch Service

手書き文字を含むスキャンされたドキュメント（PDFや画像）からテキスト情報を抽出したい場合に利用するAWSのAIサービスはどれですか？
a) Amazon Comprehend
b) Amazon Rekognition
c) Amazon Transcribe
d) Amazon Textract

(短記述式)

AWS Glueの主要な機能（コンポーネント）を2つ挙げ、それぞれの役割を簡単に説明してください。
(解答例)

c) Amazon Athena
d) Amazon Textract
AWS Glueの主要な機能：
Glueデータカタログ: データソース（S3, RDSなど）のメタデータ（テーブル定義、スキーマ情報など）を一元的に管理するリポジトリ。クローラーによって自動的に情報を収集・登録できる。Athena, Redshift Spectrum, EMRなどがこのカタログを参照してデータにアクセスする。
Glue ETLジョブ: データカタログのメタデータを利用して、データの抽出(Extract)、変換(Transform)、ロード(Load)を行うサーバーレスなETL処理を実行する機能。PythonまたはScala（Sparkベース）でジョブを記述・実行できる。
11.6 頻出キーワード
機械学習(ML) / 人工知能(AI)
Amazon Rekognition (画像/動画分析)
Amazon Transcribe (音声→テキスト)
Amazon Translate (翻訳)
Amazon Comprehend (テキスト分析/NLP) / Comprehend Medical
Amazon Forecast (時系列予測)
Amazon Lex (対話型AI/チャットボット)
Amazon Polly (テキスト→音声)
Amazon SageMaker (MLプラットフォーム)
Amazon Athena (サーバーレスSQLクエリ)
Amazon EMR (ビッグデータ処理/Spark/Hadoop)
AWS Glue (ETL/データカタログ) / Glueクローラー / Glue DataBrew
AWS Lake Formation (データレイク管理/ガバナンス)
Amazon Macie (機密データ検出)
Amazon OpenSearch Service (検索/ログ分析)
データレイク / データウェアハウス(DWH)
ETL (Extract, Transform, Load)
ストリーミング分析 (Kinesis, Flink)
PII (個人識別情報)